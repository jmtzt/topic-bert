services:
  mlflow:
    image: bert-topic
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ./efs:/app/efs
    ports:
      - "${MLFLOW_PORT:-8080}:8080"
    command: make mlflow

  train:
    image: bert-topic
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ./efs:/app/efs
      - ./results:/app/results
    environment:
      - EXPERIMENT_NAME=${EXPERIMENT_NAME:-bert_finetune_example}
      - NUM_WORKERS=${NUM_WORKERS:-1}
      - NUM_EPOCHS=${NUM_EPOCHS:-1}
      - BATCH_SIZE=${BATCH_SIZE:-2}
      - TRAIN_CONFIG=${TRAIN_CONFIG}
    command: >
      .venv/bin/python -m src.train
      --experiment-name ${EXPERIMENT_NAME}
      --train-loop-config '${TRAIN_CONFIG}'
      --num-workers ${NUM_WORKERS}
      --num-epochs ${NUM_EPOCHS}
      --batch-size ${BATCH_SIZE}
    depends_on:
      - mlflow
    shm_size: '12gb'

  serve:
    image: bert-topic
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ./efs:/app/efs
      - ./scripts:/app/scripts
    ports:
      - "${API_PORT:-8000}:8000"
    environment:
      - RUN_ID=${RUN_ID}
      - THRESHOLD=${THRESHOLD:-0.9}
    command: /bin/bash /app/scripts/start_serve.sh ${RUN_ID} ${THRESHOLD}
    depends_on:
      - mlflow
